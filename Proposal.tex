% Setup
\documentclass{article}

% Document Information
\title{Conditional WaveGAN}
\author{James Hill}
\date{}

% Document
\begin{document}

\maketitle

\section{Introduction}

Generated audio has potential practical applications such as text-to-speech and digital audio music production.
\newline
\newline
A practical audio generator would need to respond to an input and generate a corresponding output: written words could produce spoken words; digital audio commands (midi) could produce musical notes as played by a musical instrument.
\newline
\newline
Generative Adversarial Networks (Goodfellow et al., 2014) are unsupervised algorithms that have produced consistently improved results for image generation.
\newline
\newline
Recently an application of GANs to unsupervised audio generation introduced the WaveGAN model (Donahue et al., 2018) which was shown to successfully capture (and generate) words from a real data distribution for small-vocabulary speech.
\newline
\newline
In an unconditioned generative model such as that produced for the initial WaveGAN, there is no control on the modes of data being generated.
Conditioning of GANs to produce controllable generated output has been previously demonstrated on image generation applications (Mirza et al., 2014).
Mirza et al. were able to succesfully control the output of a single GAN trained generative model to output 

\section{Related Work}

Generative Adversarial Networks were recently tested for audio applications for the first time by Donahue et al.
Two strategies were tested: a frequency domain strategy and a time domain strategy.
The frequency domain strategy was based on a naive application of image generating GAN methods to spectograms.
The time domain strategy was an approach that operated on the raw audio; this was the basis of the WaveGAN model.
\newline
\newline
WaveGAN was adapted from a Deep Convolutional GAN model (Radford et al., 2016) that has been shown to produce convincing generation of scenes.

\section{References}

Donahue, Chris, McAuley, Julian, Puckette, Miller. Synthesizing Audio with Generative Adversarial Networks.
\newline
\newline
Goodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley, David, Ozair, Sherjil, Courville, Aaron, and Bengio, Yoshua. Generative adversarial networks. In NIPS, 2014.
\newline
\newline
Radford, Alec, Metz, Luke, and Chintala, Soumith. Unsupervised representation learning with deep convolutional generative adversarial networks. In ICLR, 2016.

% Wrapup
\end{document}
