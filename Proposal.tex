% Setup
\documentclass[a4paper, titlepage]{article}

% Packages
\usepackage{hyperref}
\usepackage[hyphenbreaks]{breakurl}
\usepackage{soul}
\usepackage[nottoc, numbib]{tocbibind}
\usepackage[dvipsnames]{xcolor}

% Preamble
\hypersetup{hidelinks}

% Document Information
\title{Audio Sample Selection with Generative Adversarial Networks}
\author{James Hill}
\date{}

% Document
\begin{document}

\maketitle
\tableofcontents

\newpage

\section{Introduction}

Generative Adversarial Networks (GANs) \cite{2014arXiv1406.2661G} are a type of generative neural network invented in 2014 and currently the subject of research.
The first of these networks generated novel images and newer models have shown consistently improved results for visual applications.
\newline
\newline
Sound generation has more recently become an area of research for GANs.
Generated audio has practical applications such as natural sounding text-to-speech and realistically dynamic synthesizers for digital audio music production.
Existing models such as WaveGAN \cite{2018arXiv180204208D} successfully capture recorded words from a real data distribution for small-vocabulary speech and randomly generate audio words similar to those in the dataset.
\newline
\newline
A practical audio generator however must respond to an input and generate a corresponding determined output: written words must produce spoken words; sound pitches must produce musical notes.
Methods of determining the output of a GAN have already been introduced and demonstrated for visual applications \cite{2014arXiv1411.1784M}.
This project will attempt to demonstrate output selection with an audio generating GAN.

\newpage

\section{Related Work}

Generative neural network models are powerful methods for making models understand a data distribution.
They can provide important insight into the relationship between input variables and corresponding representations.
They also have practical applications such as image denoising, inpainting, and super resolution, among others \cite{openai_blog_2017}.
\newline
\newline
There are a number of different generative models such as Botzmann machines and their variants, and deep belief networks.
Difficulties arising from using these models include the requirement to use approximations of intractable probabilistic computations, such as Markov Chains.
Another difficulty is the requirement for feedback loops during the generation process.
The GAN model was proposed so as to sidestep these difficulties.
\newline
\newline
Within a GAN model, a generator network is pitted against a discriminator network in a competition that drives both to improve.
In the simplest form, the competition is a zero-sum minimax game where the discriminator is trained to maximize the probability of assigning correct labels to training examples and generated samples, and the generator is trained to minimize this probability.
\newline
\newline
Initial experiments with GANs tended to focus on image generation with audio generation appearing later.
The reasons for this we speculate are: the availability of suitable image datasets and lack of suitable audio datasets when GANs were first subject to experiment; the fact that very small images convey more information to the human subject than very short sounds despite being of similar bit size; and the suitability of images for printed reporting of results.
\newline
\newline
Demand for applications of speech synthesis, generating speech with computers, has largely been based on a so-called concatenative text-to-speech methods and only recently were generative network models introduced with Deep Mind's WaveNet model \cite{waveNetUrl}.
WaveNet was introduced as an autoregressive model operating directly on raw audio waveform \cite{DBLP:journals/corr/OordDZSVGKSK16} (an adaptation can generate musical notes \cite{2017arXiv170401279E}).
\newline
\newline
Generative Adversarial Networks have also been recently applied to the problem of audio generation \cite{2018arXiv180204208D}.
Two strategies were tested: a frequency domain strategy based on naive application of image generating GAN methods to spectograms representing audio; and a time domain strategy operating on raw audio.
The time domain strategy was shown to produce superior results and is the foundation of the WaveGAN model.
The architecture of the WaveGAN model was adapted from a deep convolutional GAN model that was shown to generate convincing images of faces of bedrooms \cite{2015arXiv151106434R}.
\newline
\newline
Early experiments on GANs focussed exclusively on unconditioned generative models with no control on the data being generated.
Conditioning of GANs to produce controllable generated data has since been demonstrated for image and textual tag generation \cite{2014arXiv1411.1784M}.
These first conditional GANs succesfully controlled data generation by conditioning both the generator and discriminator on an extra input layer.
\newline
\newline
A recently proposed alternative approach to conditioning GANs is the Controllable GAN (CGAN) which has been demonstrated with image generation \cite{2017arXiv170800598L}.
CGAN uses a three network model with a classifier/encoder network introduced alongside the generator/decoder and discriminator networks.
The networks conduct a three-player game where the generator attempts to deceive the discriminator and also be classified to the correct corresponding class by the classifier.

\newpage

\section{Aims}

The goal of the current project is to produce a conditioned GAN capable of generating audio samples.
The resulting model will build upon the audio generating architecture of the WaveGAN model and the introduction of a third input layer as demonstrated by the Conditioned and Controllable GAN models.
Generated audio samples from the model will be evaluated against those produced by a baseline unconditioned model with the expectation that the conditioned model will produce inferior samples.

\newpage

\section{Objectives}

\begin{itemize}
\item Create the initial Downsampled Binary dataset.
\item Train the WaveGAN discriminator.
\item Train the full WaveGAN model.
\item Evaluate the performance of the full WaveGAN model compared to original paper.
\item Create the input layer for the Conditioned WaveGAN model.
\item Train the Conditioned WaveGAN model.
\item Evaluate results of both models against each other.
\item Produce Jupyter output of example samples from both models to accompany the final report.
\item Consider further repetitions of the experiment.
\end{itemize}

\newpage

\section{Methodology}

\subsection{Dataset Creation}

The first of the datasets that I propose I name \textit{Downsampled Speech Commands Binary}.
This is the smallest dataset I propose and includes only the words for the numbers 'zero' and 'one' from the original \textit{Speech Commands Dataset}.
With only two different modes of data to discriminate between and generate, this is the simplest possible dataset which can be used to perform this experiment.
It is a neat dataset as it conforms to the binary numbers, has words of different syllabile count, and is also a subset of the \textit{Speech Commands Zero Through Nine} (SC09) introduced by Donahue et al.
\newline
\newline
This dataset is a subset of the previously existing \textit{Speech Commands Dataset} \cite{speechcommands} published by Google.
A difference between this dataset and the original dataset is that all audio samples will be downsampled in order to decrease their size and the computational cost of running the experiments.
\newline
\newline
The downsampled versions of these datasets downsample the audio files from 16000 samples per second.
Each cycle requires two samples to be recorded, so audio with 16000 samples per second is able to capture 8000hz.
The most recognisable frequencies of the human voice which are identifiable as speech are within a range up to 3000hz or 4000hz.
Downsampling to cover these ranges would therefore take the audio file samples per second from 16000 samples per second to between 6000 to 8000 samples per second.
Downsampling to 3000hz leaves a still recognizable voice and words but the resulting is noticeably 'deeper' and subjectively unnatural compared to sampeles at 4000hz.
\newline
\newline
The purpose of downsampling is to reduce the size of the samples that the neural networks need to be trained on: this is equivalent to using smaller image sizes for testing the training of convolution neural networks for image recognition.
These proposed downsampled and limited datasets are therefore more computationally cost efficient and less expensive to experiment on; a real benefit for students of deep learning who will likely have no free access to the powerful GPUs that many deep learning experiments are run on.
\newline
\newline
Reduction of the sample file size to 6000 rather than 8000 samples per second is therefore more desirable for the purpose of creating a more computationally cost efficient experiment.
However, the relatively unnatural sound of lower sample rates could potentially have an impact on any experiment evaluation involving human subjects listening and comparing audio samples.
For example, if the subject was requested to evaluate how natural a generated audio sample compares to a recorded sample, the noticeably lower audio quality of the 3000hz samples could confound the results: the subject may consider even the recorded sample to sound generated.

\subsection{Baseline WaveGAN}

Initially, a replica of the initial unsupervised WaveGAN will be trained.
It will use near identical structure and hyperparameters as the model produced by Donahue et al.
Unlike the original model it will be trained only on the words for two numbers from the dataset, 'zero' and 'one', as contained in the \textit{Downsampled Speech Commands Binary} dataset.
\newline
\newline
The process of creating this initial model will allow for familiarization of the process of producing a mode from code to runtime; any difficulties encountered should be encountered and overcome within a simplified setting.
Elements of this model such as the discriminator will also be resuable for the conditioned and controlled versions of the WaveGAN.
\newline
\newline
The models will be designed with the TensorFlow machine intelligence package for Python programming language.

\subsubsection{Train the WaveGAN discriminator}

How accurate does this discriminator need to be?

\subsubsection{Train the full WaveGAN model}

\subsubsection{Evaluate the performance of the WaveGAN model}

Audio is difficult to represent visually so an interactive notebook will also be produced that will allow readers to listen to samples of the audio and compare the results.
This will allow the reader of the final reprot to also make a subjective evaluation of the results.
\newline
\newline
Nonetheless, as shown by Engel et al. it is still possible demonstrate differences between audio visually through the use of 'rainbowgrams'; constant-q transform (CQT) plots of the audio.
These 'rainbowgrams' will therefore also be explored during the evaluation for possible visible differences in the generated and real data samples and will be produced in the final report if they produce interesting comparisons.
\newline
\newline
The Inception Score is another form of evaluation that can be used for comparing generated samples against real data samples and has been used in a number of experiments for generative adversarial networks.
Concerns have been recently raised about the validity of the Inception Score but as there is currently no other comparable alternative it will need to be used in this experiment but with some caution applied to interpretation of the results.
\newline
\newline
Analysis of results will use a statistical language such as Python with extensions or possibly R programming language.

\subsection{Conditioned WaveGAN}

The second model will introduce conditioning into the original model.
The new model will be a WaveGAN but with the introduction of an additional input layer that conditions the randomly generated input.

\subsubsection{Create the Input layer for the Conditioned WaveGAN model}

\subsubsection{Train the Conditioned WaveGAN model}

\subsubsection{Evaluate the performance of the Conditioned WaveGAN model}

Once complete, the model will be evaluated against the Baseline model; it's expected (given the results of the initial Conditioned GAN created by Mirza et al.) that this model will intially produce generated samples less powerful than those created by the baseline WaveGan.
This is acceptable as future exploration of the hyperparameters out of the scope of this experiment would be necessary as to produce better models.
\newline
\newline
In any case, generated samples from both of the conditioned models will be compared against each other and to the samples generated from the baseline WaveGAN.
\newline
\newline
Subjective evaluation is an appropriate approach for generational models and human assessment of random samples by subjects may be used, particularly to obtain preferences between the Conditional WaveGAN and Controlled WaveGAN.
However, due to the requirements of using human samples, having to get sign off for experimentation, having to create an interface to produce the tests, collecting subjects and getting them to respond, it has been decided that this is not possible within the time frame allowed for this project.
Evaluation will therefore be based purely on metrics.
\newline
\newline
Audio samples used in the evaluation of the results will be presented in a Jupyter Notebook format so that the reader may form their own judgement of the quality difference between outputs from each model.

\subsection{Consideration of further work if time permits}

There are a number of possible directions for further exploration of the project if it runs ahead of time.
Which particular direction is chosen will be dependent on factors such as: how much time is left; what does the initial experiment suggest will be either an interesting or feasible direction?
Englargement of the dataset and increasing the sample rate of the audio are both simple changes to the experiment; it is possible that both could be implemented at the same time if it appears feasible.
Increasing the sample rate would be a simple change to make, and would allow for more accurate evaluation of the results, but would not add much to the experiment
Enlargement of the dataset used for the training should be more interesting to evaluate as it is testing a more substantial difficulty; more complex data resulting in a more complex and difficult model.
Attempting to replicate the third model would also produce very interesting results but may be challenging to perform within the project time frame.

\subsubsection{Increasing the Sample rate of audio used}

An alternative would be to increase the sample rate of the audio for a rerun of the experiment.
A rerun with higher quality audio should give a firmer basis for the results of the experiment.
More detailed and clearer audio samples will allow for better evaluation of the results.

\subsubsection{Enlargement of the dataset used for training}

Once all models have been produced and initially evaluated, an enlargement of the number of words used for their training will be considered.
The experiment should first be replicated with the \textit{Downsampled Speech Commands Directions} dataset.
This dataset contains four directional commands from the \textit{Speech Commands Dataset}: 'up', 'down', 'left' and 'right'.
This dataset is double the size of the \textit{Downsampled Speech Commands Binary} dataset so will be used to expand the complexity of the experiment while still being limited enough to restrict potential computational cost.

\subsubsection{Attempting a third model}

Another possibility would be to train a third model: a Controlled GAN trained on the same dataset of spoken 'zero' and 'one'.
If successful then the model will be evaluated for quality against both the baseline model and the Conditioned GAN.
It is again expected that the initial model would be inferior to the baseline model.
However, it will be interesting to compare against the Conditioned WaveGAN as a claim has been made that it should be a superior method for training GANs with conditioning.
However, a difficulty with attempting this third model is that the paper in which it is described is fairly scanty on details of the architecture.
\newline
\newline
Evaluation of the results would then be required on the final sets of generated samples: between the Conditional WaveGAN and baseline WaveGAN; between the Controlled WaveGAN and baseline WaveGAN; and between the Conditional WaveGAN and Controlled WaveGAN.

\newpage

\section{Potential Difficulties}

The initial WaveGAN model was run for 4 days on an NVIDIA P100 GPU before converging (on sale for upwards of £6k at the time of writing).
It is possible that this level of processing power will not be available.
Downsampling of the original dataset is one method to ameliorate this problem.
\newline
\newline
However, the experiment can prove the concept of a conditional WaveGAN without using the full dataset used for the creation of the initial WaveGAN.
The initial dataset for WaveGAN used words for numbers 'zero' through 'nine'.
To reduce the computational requirements a lower count of words may be chosen for the experiment.
Two words, 'zero' and 'one' can be used to prove that the models work and should allow for comparison of generated sample quality.
If the models are successful and if it seems sensible then the number of words used for the training of the models may be increased.
\newline
\newline
Secondly, in order to reduce the amount of data to be processed, the experiment may also use downsampled versions of the dataset.
Downsampling of audio reduces the definition and perceived quality (at least at the lower sample rates that might be needed in this case) but will reduce the amount of data to be trained in the networks.
This shouldn't limit the validity of the experiment because perceived audio quality is not a key measurement; the difference in quality between models is of prime importance.

\newpage

\section{Time Plan}

Write here a detailed and realistic plan of how long each section of the project is likely to take.

\newpage

\section{Finance}

The financing of a deep learning experiment must be taken into consideration as the cost of computation can be expensive.
For example, the training of the original WaveGAN network by Donahue et al. required four days of calculation on an NVIDIA P100 GPU before convergence.
At the time of writing, an NVIDIA P100 GPU is on sale for approximatley \$5,500 on Amazon.com.
It is therefore essential to bring down the potential cost of the experiment.
\newline
\newline
The creation of downsampled datasets for running the experiment is the first method of reducing the overall cost.
Downsampling can reduce the datasets to between 3/8s and 1/2 of the original size and should result in a similar reduction of the computation.
\newline
\newline
The reduction of the number of modes of the data from ten in the original \textit{Speech Commands Zero Through Nine} dataset to two in the proposed \textit{Downsampled Speech Commands Binary} dataset and four in the \textit{Downsampled Speech Commands Directions} will also decrease the cost of the experiment.
The two mode dataset could reduce the final computation time to one fifth of the original undertaken by Donahue et al. while the four mode dataset would be two fifths of the computation time.
\newline
\newline
With the proposed downsampling rates and limited datasets, the final time requirement for training of the initial WaveGAN on a similarly powered GPU could potentially be brought down to between 3/40ths and 1/5th.
\newline
\newline
A GPU is available for use in this experiment: it is an NVIDIA GPU that can be used with CUDA (Compute Unified Device Architecture) with a compute capability of 2.1 (compared to a compute capability of 6.0 for an NVIDIA P100 GPU.
This is a substantially less powerful GPU but may be useful for at least running trials and the training of simpler models such as the discriminator networks for the variations on the WaveGAN model.
\newline
\newline
Where the available GPU is insufficient, the experiment can be performed on cloud GPU.
For example, at the time of writing, \href{https://cloud.google.com/gpu/}{Google Cloud} has NVIDIA P100 GPUs available at \$0.73 for preemptible instances that can be used for batch based processing.
There are other services available such as Amazon Web Services: the choice of service will need to consider the ease of use of the service, compatibility with the tools being used, and the relative pricing at time of running the experiment.

\newpage
% Bibliography
\bibliography{Bibliography}
\bibliographystyle{ieeetr}

% Wrapup
\end{document}
