% Setup
\documentclass[a4paper, titlepage]{article}

% Packages
\usepackage{hyperref}
\usepackage[hyphenbreaks]{breakurl}
\usepackage{soul}
\usepackage[nottoc, numbib]{tocbibind}
\usepackage[dvipsnames]{xcolor}

% Preamble
\hypersetup{hidelinks}

% Document Information
\title{Audio Sample Selection with Generative Adversarial Networks}
\author{James Hill}
\date{}

% Document
\begin{document}

\maketitle
\tableofcontents

\newpage

\section{Introduction}

Generated audio has potential practical applications such as text-to-speech and digital audio music production.
A practical audio generator would need to respond to an input and generate a corresponding output: written words could produce spoken words; digital audio commands (midi) could produce musical notes as played by a musical instrument.
\newline
\newline
Generative Adversarial Networks \cite{2014arXiv1406.2661G} are unsupervised algorithms that have produced consistently improved results for image generation.
Recently an application of GANs to unsupervised audio generation introduced the WaveGAN model \cite{2018arXiv180204208D} which was shown to successfully capture (and generate) words from a real data distribution for small-vocabulary speech.
\newline
\newline
In an unsupervised generative model such as the initial WaveGAN there is no control on the modes of data (output) being generated.
There are now two proposed models for controlling the output of a GAN: Conditional GAN and Controllable GAN but it has not yet been demonstrated which is most capable of giving the best results.
\newline
\newline
The goal of the project is to produce the best possible WaveGAN model capable of generating controlled outputs as using either of the two methodologies for achieving this.
An essential part of the project is to determine through experimentation which of these will produce the best results.
\newline
\newline
This project will be submitted to complete the MSc Intelligent Technologies pathway of the MSc Advanced Computing Technologies degree.
The work builds from the theoretical foundations provided in the Intelligent Technologies module (now Machine Learning) which is taught by George Magoulas.

\section{Related Work}

Deep neural network models have already been applied to the problem of audio generation: the WaveNet autoencoder \cite{DBLP:journals/corr/OordDZSVGKSK16} was introduced as an autoregressive model operating directly on raw audio waveform; this has been further developed into a model that can generate musical notes \cite{2017arXiv170401279E}.
\newline
\newline
\textcolor{red}{
  Why are GANs more interesting than other generative models (LeCun).
  More general information on exactly how GANs work.
  Discuss the architecture in more detail.
  Discuess the competitive min/max game.
  Discuss how they have been applied to other types of data.
}
\newline
\newline
\textcolor{red}{
  Explain why audio has been less used than images for GANs.
  Explain how there have been naive attempts to recreate audio as image files.
  Explain how new methods of using GANs for audio are using signal processing.
}
\newline
\newline
Generative Adversarial Networks have also been recently tested for audio generation \cite{2018arXiv180204208D}.
Two strategies were tested: a frequency domain strategy and a time domain strategy.
The frequency domain strategy was based on a naive application of image generating GAN methods to spectograms.
The time domain strategy was an approach that operated on the raw audio; this was the basis of the WaveGAN model.
WaveGAN was adapted from a Deep Convolutional GAN model \cite{2015arXiv151106434R} that has been shown to produce convincing generation of scenes.
\newline
\newline
Conditioning of GANs to produce controllable generated output was first demonstrated on image generation applications \cite{2014arXiv1411.1784M}.
Mirza et al. were able to succesfully control the output of a single GAN trained generative model by inserting 1-hot vectors alongside random input into the generator.
\newline
\newline
A recently proposed and tested approach is the Controllable Generative Adversarial Network \cite{2017arXiv170800598L}.
CGAN uses a three network model with a classifier network introduced alongside the regular generator and discriminator.
Examples of compared output from both conditional and controllable GANs are shown in the paper but no rigorous evaluation is offered.
\newline
\newline
\textcolor{red}{
  Explain issues around the evaluation of GANs.
}
\newline
\newline
Controllable audio generative adversarial networks are important as they can be the foundation of future audio synethesizers.
A synthesizer is a digital audio generator that can produce sounds that haven't bee n previously recorded.
Existing synthesizer architectures include analogue (which can be emulated digitally), FM, and physical modelling.
One motivation for producing synthesizers is to recreate the sound of real world mechanical instruments.
Over time the realism and naturalism of synthesizers has increased.
Generative Adversarial Networks however have the potential to introduce new levels of realism and naturalness while being easier to create than the currently most-realistic physically modelled synthesizers.
\newline
\newline
A GAN-based synthesizer would be a model that can be controlled by musical pitch while reproducing realistic sounds.
Synthesizers also are controlled on other dimensions to increase the realism and playability of the sound, such as velocity (which relates to the force with which a musical note is played on the keyboard or other input).

\section{Aims}

The goal of this project is to produce a working controllable generative adversarial model for audio based upon the WaveGAN architecture and to evaluate it's output in relation to the first model.

\section{Objectives}

\begin{itemize}
\item Create the initial Downsampled Binary dataset.
\item Train the WaveGAN discriminator.
\item Train the full WaveGAN model.
\item Evaluate the performance of the full WaveGAN model compared to original paper.
\item Create the input layer for the Conditioned WaveGAN model.
\item Train the Conditioned WaveGAN model.
\item Evaluate results of both models against each other.
\item Produce Jupyter output of example samples from both models to accompany the final report.
\item Consider further repetitions of the experiment.
\end{itemize}

\section{Methodology}

\subsection{Dataset Creation}

The first of the datasets that I propose I name \textit{Downsampled Speech Commands Binary}.
This is the smallest dataset I propose and includes only the words for the numbers 'zero' and 'one' from the original \textit{Speech Commands Dataset}.
With only two different modes of data to discriminate between and generate, this is the simplest possible dataset which can be used to perform this experiment.
It is a neat dataset as it conforms to the binary numbers, has words of different syllabile count, and is also a subset of the \textit{Speech Commands Zero Through Nine} (SC09) introduced by Donahue et al.
\newline
\newline
This dataset is a subset of the previously existing \textit{Speech Commands Dataset} \cite{Google_Research_blog_2017} published by Google.
A difference between this dataset and the original dataset is that all audio samples will be downsampled in order to decrease their size and the computational cost of running the experiments.
\newline
\newline
The downsampled versions of these datasets downsample the audio files from 16000 samples per second.
Each cycle requires two samples to be recorded, so audio with 16000 samples per second is able to capture 8000hz.
The most recognisable frequencies of the human voice which are identifiable as speech are within a range up to 3000hz or 4000hz.
Downsampling to cover these ranges would therefore take the audio file samples per second from 16000 samples per second to between 6000 to 8000 samples per second.
Downsampling to 3000hz leaves a still recognizable voice and words but the resulting is noticeably 'deeper' and subjectively unnatural compared to sampeles at 4000hz.
\newline
\newline
The purpose of downsampling is to reduce the size of the samples that the neural networks need to be trained on: this is equivalent to using smaller image sizes for testing the training of convolution neural networks for image recognition.
These proposed downsampled and limited datasets are therefore more computationally cost efficient and less expensive to experiment on; a real benefit for students of deep learning who will likely have no free access to the powerful GPUs that many deep learning experiments are run on.
\newline
\newline
Reduction of the sample file size to 6000 rather than 8000 samples per second is therefore more desirable for the purpose of creating a more computationally cost efficient experiment.
However, the relatively unnatural sound of lower sample rates could potentially have an impact on any experiment evaluation involving human subjects listening and comparing audio samples.
For example, if the subject was requested to evaluate how natural a generated audio sample compares to a recorded sample, the noticeably lower audio quality of the 3000hz samples could confound the results: the subject may consider even the recorded sample to sound generated.

\subsection{Baseline WaveGAN}

Initially, a replica of the initial unsupervised WaveGAN will be trained.
It will use near identical structure and hyperparameters as the model produced by Donahue et al.
Unlike the original model it will be trained only on the words for two numbers from the dataset, 'zero' and 'one', as contained in the \textit{Downsampled Speech Commands Binary} dataset.
\newline
\newline
The process of creating this initial model will allow for familiarization of the process of producing a mode from code to runtime; any difficulties encountered should be encountered and overcome within a simplified setting.
Elements of this model such as the discriminator will also be resuable for the conditioned and controlled versions of the WaveGAN.
\newline
\newline
The models will be designed with the TensorFlow machine intelligence package for Python programming language.

\subsubsection{Train the WaveGAN discriminator}

How accurate does this discriminator need to be?

\subsubsection{Train the full WaveGAN model}

\subsubsection{Evaluate the performance of the WaveGAN model}

Audio is difficult to represent visually so an interactive notebook will also be produced that will allow readers to listen to samples of the audio and compare the results.
This will allow the reader of the final reprot to also make a subjective evaluation of the results.
\newline
\newline
Nonetheless, as shown by Engel et al. it is still possible demonstrate differences between audio visually through the use of 'rainbowgrams'; constant-q transform (CQT) plots of the audio.
These 'rainbowgrams' will therefore also be explored during the evaluation for possible visible differences in the generated and real data samples and will be produced in the final report if they produce interesting comparisons.
\newline
\newline
The Inception Score is another form of evaluation that can be used for comparing generated samples against real data samples and has been used in a number of experiments for generative adversarial networks.
Concerns have been recently raised about the validity of the Inception Score but as there is currently no other comparable alternative it will need to be used in this experiment but with some caution applied to interpretation of the results.
\newline
\newline
Analysis of results will use a statistical language such as Python with extensions or possibly R programming language.

\subsection{Conditioned WaveGAN}

The second model will introduce conditioning into the original model.
The new model will be a WaveGAN but with the introduction of an additional input layer that conditions the randomly generated input.

\subsubsection{Create the Input layer for the Conditioned WaveGAN model}

\subsubsection{Train the Conditioned WaveGAN model}

\subsubsection{Evaluate the performance of the Conditioned WaveGAN model}

Once complete, the model will be evaluated against the Baseline model; it's expected (given the results of the initial Conditioned GAN created by Mirza et al.) that this model will intially produce generated samples less powerful than those created by the baseline WaveGan.
This is acceptable as future exploration of the hyperparameters out of the scope of this experiment would be necessary as to produce better models.
\newline
\newline
In any case, generated samples from both of the conditioned models will be compared against each other and to the samples generated from the baseline WaveGAN.
\newline
\newline
Subjective evaluation is an appropriate approach for generational models and human assessment of random samples by subjects may be used, particularly to obtain preferences between the Conditional WaveGAN and Controlled WaveGAN.
However, due to the requirements of using human samples, having to get sign off for experimentation, having to create an interface to produce the tests, collecting subjects and getting them to respond, it has been decided that this is not possible within the time frame allowed for this project.
Evaluation will therefore be based purely on metrics.
\newline
\newline
Audio samples used in the evaluation of the results will be presented in a Jupyter Notebook format so that the reader may form their own judgement of the quality difference between outputs from each model.

\subsection{Consideration of further work if time permits}

There are a number of possible directions for further exploration of the project if it runs ahead of time.
Which particular direction is chosen will be dependent on factors such as: how much time is left; what does the initial experiment suggest will be either an interesting or feasible direction?
Englargement of the dataset and increasing the sample rate of the audio are both simple changes to the experiment; it is possible that both could be implemented at the same time if it appears feasible.
Increasing the sample rate would be a simple change to make, and would allow for more accurate evaluation of the results, but would not add much to the experiment
Enlargement of the dataset used for the training should be more interesting to evaluate as it is testing a more substantial difficulty; more complex data resulting in a more complex and difficult model.
Attempting to replicate the third model would also produce very interesting results but may be challenging to perform within the project time frame.

\subsubsection{Increasing the Sample rate of audio used}

An alternative would be to increase the sample rate of the audio for a rerun of the experiment.
A rerun with higher quality audio should give a firmer basis for the results of the experiment.
More detailed and clearer audio samples will allow for better evaluation of the results.

\subsubsection{Enlargement of the dataset used for training}

Once all models have been produced and initially evaluated, an enlargement of the number of words used for their training will be considered.
The experiment should first be replicated with the \textit{Downsampled Speech Commands Directions} dataset.
This dataset contains four directional commands from the \textit{Speech Commands Dataset}: 'up', 'down', 'left' and 'right'.
This dataset is double the size of the \textit{Downsampled Speech Commands Binary} dataset so will be used to expand the complexity of the experiment while still being limited enough to restrict potential computational cost.

\subsubsection{Attempting a third model}

Another possibility would be to train a third model: a Controlled GAN trained on the same dataset of spoken 'zero' and 'one'.
If successful then the model will be evaluated for quality against both the baseline model and the Conditioned GAN.
It is again expected that the initial model would be inferior to the baseline model.
However, it will be interesting to compare against the Conditioned WaveGAN as a claim has been made that it should be a superior method for training GANs with conditioning.
However, a difficulty with attempting this third model is that the paper in which it is described is fairly scanty on details of the architecture.
\newline
\newline
Evaluation of the results would then be required on the final sets of generated samples: between the Conditional WaveGAN and baseline WaveGAN; between the Controlled WaveGAN and baseline WaveGAN; and between the Conditional WaveGAN and Controlled WaveGAN.

\section{Potential Difficulties}

The initial WaveGAN model was run for 4 days on an NVIDIA P100 GPU before converging (on sale for upwards of £6k at the time of writing).
It is possible that this level of processing power will not be available.
Downsampling of the original dataset is one method to ameliorate this problem.
\newline
\newline
However, the experiment can prove the concept of a conditional WaveGAN without using the full dataset used for the creation of the initial WaveGAN.
The initial dataset for WaveGAN used words for numbers 'zero' through 'nine'.
To reduce the computational requirements a lower count of words may be chosen for the experiment.
Two words, 'zero' and 'one' can be used to prove that the models work and should allow for comparison of generated sample quality.
If the models are successful and if it seems sensible then the number of words used for the training of the models may be increased.
\newline
\newline
Secondly, in order to reduce the amount of data to be processed, the experiment may also use downsampled versions of the dataset.
Downsampling of audio reduces the definition and perceived quality (at least at the lower sample rates that might be needed in this case) but will reduce the amount of data to be trained in the networks.
This shouldn't limit the validity of the experiment because perceived audio quality is not a key measurement; the difference in quality between models is of prime importance.

\section{Time Plan}

Write here a detailed and realistic plan of how long each section of the project is likely to take.

\section{Finance}

The financing of a deep learning experiment must be taken into consideration as the cost of computation can be expensive.
For example, the training of the original WaveGAN network by Donahue et al. required four days of calculation on an NVIDIA P100 GPU before convergence.
At the time of writing, an NVIDIA P100 GPU is on sale for approximatley \$5,500 on Amazon.com.
It is therefore essential to bring down the potential cost of the experiment.
\newline
\newline
The creation of downsampled datasets for running the experiment is the first method of reducing the overall cost.
Downsampling can reduce the datasets to between 3/8s and 1/2 of the original size and should result in a similar reduction of the computation.
\newline
\newline
The reduction of the number of modes of the data from ten in the original \textit{Speech Commands Zero Through Nine} dataset to two in the proposed \textit{Downsampled Speech Commands Binary} dataset and four in the \textit{Downsampled Speech Commands Directions} will also decrease the cost of the experiment.
The two mode dataset could reduce the final computation time to one fifth of the original undertaken by Donahue et al. while the four mode dataset would be two fifths of the computation time.
\newline
\newline
With the proposed downsampling rates and limited datasets, the final time requirement for training of the initial WaveGAN on a similarly powered GPU could potentially be brought down to between 3/40ths and 1/5th.
\newline
\newline
A GPU is available for use in this experiment: it is an NVIDIA GPU that can be used with CUDA (Compute Unified Device Architecture) with a compute capability of 2.1 (compared to a compute capability of 6.0 for an NVIDIA P100 GPU.
This is a substantially less powerful GPU but may be useful for at least running trials and the training of simpler models such as the discriminator networks for the variations on the WaveGAN model.
\newline
\newline
Where the available GPU is insufficient, the experiment can be performed on cloud GPU.
For example, at the time of writing, \href{https://cloud.google.com/gpu/}{Google Cloud} has NVIDIA P100 GPUs available at \$0.73 for preemptible instances that can be used for batch based processing.
There are other services available such as Amazon Web Services: the choice of service will need to consider the ease of use of the service, compatibility with the tools being used, and the relative pricing at time of running the experiment.

\newpage
% Bibliography
\bibliography{Bibliography}
\bibliographystyle{ieeetr}

% Wrapup
\end{document}
